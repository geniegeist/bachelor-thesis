

\chapter{Distribution Theory}

In distribution theory one is interested in... 

The beauty of \cite{caravenna2021hairer}, on which this bachelor thesis is based, lies within the fact that the Reconstruction Theorem can be stated in terms of elementary distribution theory without the need of regularity structures. 

The first concept we will encounter is that of a \emph{support} of a function \(\varphi: \mathbb{R}^d \to \mathbb{R}\), which is defined as \(\mathrm{supp}(\varphi) = \overline{\left\{ x \in \mathbb{R}^d : \varphi(x) \neq 0 \right\}}\). 

\begin{definition}[Test Function]
    \emph{Test functions} \(\varphi: \mathbb{R}^d \to \mathbb{R}\) are smooth functions that have compact support. The \emph{space of test functions} \(\mathcal{D}\) is the set that contains all test functions:
    \begin{align*}
        \mathcal{D} = \mathcal{D}(\mathbb{R}^d) &= \left\{ \varphi \in C^\infty(\mathbb{R}^d) : \text{\(\mathrm{supp}(\varphi)\) is compact} \right\}, \\
        \mathcal{D}(A) &= \left\{ \varphi \in \mathcal{D} : \mathrm{supp}(\varphi) \subset A \right\} \qquad \text{for any subset \(A \subset \mathbb{R}^d\).}
    \end{align*}
\end{definition}

A standard example for a test function is the \emph{bump function}:
\begin{align*}
    \mathcal{B}(x) = \begin{cases}
        \exp{\left( -\frac{1}{1 - |x|^2} \right)}, \quad & |x| < 1, \\
        0, & \text{otherwise}.
    \end{cases}
\end{align*}
Clearly, the bump function has compact support in \(B(0,1)\). The proof that it is smooth can be found in any standard analysis book, e.g. see (22.2) in \cite{Forster_2016}.

The main object of study of Distribution Theory is unsuprisingly a \emph{distribution}.
\begin{definition}[Distribution]
A functional \(u: \mathcal{D} \to \mathbb{R}\) is called a \emph{distribution} if \(u\) is linear, and if for every compact set \(K \subset \mathbb{R}^d\) there exist \(r \in \mathbb{N}_0\) and \(C < \infty\) such that 
\begin{align*}
    |u(\varphi)| \leq C \lVert\varphi\rVert_{C^r}, \quad \forall \varphi \in \mathcal{D}(K).
\end{align*}
The \emph{space of all distributions} is denoted \(\mathcal{D}' = \left\{ u: \mathcal{D} \to \mathbb{R} \, | \, \text{\)u\( is a distribution} \right\}\).
\end{definition}

Next, we give \emph{convergence in \(\mathcal{D}\)} a meaning.

\begin{definition}[Convergence]
    Let \((\varphi_j)\) be a sequence in \(\mathcal{D}\) and \(\varphi \in \mathcal{D}\). We say $
        \varphi_j \to \varphi  \text{ in \(\mathcal{D}\)}
    $
    if 
    \begin{enumerate}[label=(\roman*)]
        \item there exists a compact set \(K \in \mathbb{R}^d\) such that \(\mathrm{supp}(\varphi)\) and \(\mathrm{supp}(\varphi_j)\) are contained in \(K\) for all \(j\), and 
        \item \(\lVert \varphi_j - \varphi \rVert_{C^r} \to 0\) as \(j \to \infty\) for all \(r \in \mathbb{N}_0\).
    \end{enumerate} 
\end{definition}

This allows us to give an alternative characterization of distributions: a distribution is a linear functional that is \emph{continuous}.

\begin{lemma}
    Let \(u: \mathcal{D} \to \mathbb{R}\) be a linear functional. Then, \(u\) is a {distribution} if and only if \(\varphi_j \to \varphi\) in \(\mathcal{D}\) implies \(u(\varphi_j) \to u(\varphi)\) for all test functions \(\varphi_j\) and \(\varphi\).
\end{lemma}

\begin{proof}
    Let \(u\) be a distribution and \(\varphi_j \to \varphi\) in \(\mathcal{D}\). Then, there exist \(C\) and \(r\) such that \(|u(\varphi_j -\varphi)| \leq C \lVert \varphi_j - \varphi \rVert_{C^r} \to 0\) as \(j \to \infty\) . By linearity, it follows \(u(\varphi_j) \to u(\varphi)\).

    For the converse direction, we argue by contradiction. Let \(\varphi_j \to \varphi\) in \(\mathcal{D}\) imply \(u(\varphi_j) \to u(\varphi)\) for all test functions \(\varphi_j\) and \(\varphi\). Assume, there is a compact set \(K \subset \mathbb{R}^d\) such that for all \(r \in \mathbb{N}_0\) and \(C < \infty\) the inequality \(|u(\varphi)| \leq C \lVert\varphi\rVert_{C^r}\) is violated for some \(\varphi \in \mathcal{D}\). Then, we can find \(\varphi_n\) with \(|u(\varphi_n)| > n \lVert \varphi_n \rVert_{C^n}\) for all \(n \in \mathbb{N}\). Next, we define \(\phi_n \coloneqq \frac{\varphi_n}{n \lVert \varphi_n \rVert_{C^n}}\). So, we get \(u(\phi_n) > 1\). However, \(\phi_n \to 0\) in \(\mathcal{D}\) as \(n \to \infty\) because \(\lVert \phi_n \rVert_{C^r} \leq \frac{1}{n}\) for all \(n \geq r\).
\end{proof}

Quite often, we are given a test function \(\varphi\), and we would like to construct a sequence \((\varphi_j)\) such that \(\varphi_j \to \varphi  \text{ in \)\mathcal{D}\(}\). \emph{Mollifiers} are an indispensable tool for constructing such sequences, which we will use throughout the paper. First, we need to scale and translate arbitrary functions \(\varphi: \mathbb{R}^d \to \mathbb{R}\):
\begin{align*}
    \varphi^\epsilon_y(x) \coloneqq \frac{1}{\epsilon^d} \, \varphi\left(\frac{x-y}{\epsilon}\right), \quad \varphi^\epsilon(x) \coloneqq \varphi^\epsilon_0(x), \quad \varphi_y(x) \coloneqq \varphi^1_y(x).
\end{align*} 

Given a compactly supported function \(\rho: \mathbb{R}^d \to \mathbb{R}\) that integrates to one, a family of scaled and translated versions of \(\rho\) is called a \emph{mollifier}.

\begin{definition}[Mollifier]
    Let \(\rho: \mathbb{R}^d \to \mathbb{R}\) be a function with compact support and \(\int_{\mathbb{R}^d} \rho(x) \, \mathrm{d}x = 1\). Then, the family of scaled functions \((\rho^\epsilon)_{\epsilon > 0}\) is called a \emph{mollifier}.
\end{definition}

Constructing a sequence \((\varphi_j)\) such that \(\varphi_j \to \varphi\) in \(\mathcal{D}\) becomes an easy task with the help of mollifiers and \emph{convolutions}. The \emph{convolution} of two functions \(f,g \in {L}^1(\mathbb{R}^d)\) is defined as \((f*g)(x) = \int_{\mathbb{R}^d} f(x - y)g(y) \, \mathrm{d}y\). 

\begin{lemma}
    Let \(f,g \in {L}^1(\mathbb{R}^d)\). Then, 
    \begin{enumerate}
        \item \(f*g\) is well-defined almost everywhere, and 
        \item \(f*g \in {L}^1(\mathbb{R}^d)\).
    \end{enumerate}
\end{lemma}
\begin{proof}
    We can safely assume \(f\) and \(g\) to be representatives of the equivalence classes, because we  treat \(\int f(x) \; \mathrm{d}x\) as Lebesgue integrals and these integrals are independent of the chosen representatives.

    First, we check that \((x,y) \mapsto f(x-y)g(y) \in L^1(\mathbb{R}^d \times \mathbb{R}^d)\) in order to apply Fubini. From Tonelli's theorem and the translation invariance of the Lebesgue integral we obtain
    \begin{align*}
        \int_{\mathbb{R}^d \times \mathbb{R}^d}|f(x-y)g(y)| \, \mathrm{d}(x,y) = \int_{\mathbb{R}^d}\int_{\mathbb{R}^d} |f(x-y)g(y)| \, \mathrm{d}x \, \mathrm{d}y = \lVert f \rVert_{1} \lVert g \rVert_{1} < \infty.
    \end{align*}

    Then, by Fubini's theorem we obtain that \(y \mapsto f(x-y)g(y)\) is integrable for almost every \(x \in \mathbb{R}^d\). Thus, \((f*g)(x) = \int f(x-y)g(y) \, \mathrm{d}y\) is well-defined for almost every \(x \in \mathbb{R}^d\). Also by Fubini, \(f*g\) is integrable (if we assign zero in the points of the null set where it is not defined).
\end{proof}
Additionally, the proof also tells us that
\begin{align}
    \lVert f*g \rVert_1 \leq \lVert f \rVert_{1} \lVert g \rVert_{1}.
\end{align}

When we convolute a test function \(\varphi \in \mathcal{D}\) against a mollifier \((\rho^\epsilon)\), we obtain a sequence \((\varphi * \rho^\epsilon) \subset \mathcal{D}\) that converges to \(\varphi\) in \(\mathcal{D}\) as \(\epsilon \to 0\).  

\begin{lemma}\label{mollifier-lemma}
    Let \((\rho^\epsilon)\) be a mollifier. For all test functions \(\varphi \in \mathcal{D}\), we have
    \begin{enumerate}
        \item \(\varphi * \rho^{\epsilon} \in \mathcal{D}\) for all \(\epsilon > 0\), and
 
        \item \(\varphi * \rho^\epsilon \to \varphi  \text{ in \)\mathcal{D}\( as \)\epsilon \to 0\(}\).
    \end{enumerate}
\end{lemma}

\begin{proof}
    We first show \(\frac{\partial (\varphi * \rho^{\epsilon})}{\partial x_j} = \left(\frac{\partial \varphi}{\partial x_j}\right) * \rho^{\epsilon}\). Applying that rule inductively implies \(\varphi * \rho^{\epsilon} \in C^{\infty}\). Let \(e_j\) denote the \(j\)-th unit vector. Consider the difference quotient
    \begin{align*}
        \frac{(\varphi * \rho^\epsilon)(x + te_j) - (\varphi * \rho^\epsilon)(x)}{t} = \int \frac{\varphi(x+te_j - y) - \varphi(x-y)}{t}\rho^{\epsilon}(y) \mathrm{d}y.
    \end{align*}
    By the mean value inequality (Theorem \ref{mean-value-inequality}), we can bound
    \begin{align*}
        \frac{\varphi (x + te_j - y) - \varphi (x-y)}{t} \leq \max_{\xi \in [0,t]}\frac{\partial}{\partial x_j}\varphi(x - y + \xi e_j) \leq C
    \end{align*}
    for some \(C > 0\) since \(\varphi\) is continuously differentiable. Thus, we found an integrable function that dominates \(\frac{\varphi(x+te_j - y) - \varphi(x-y)}{t}\rho^{\epsilon}(y)\), and we can apply Lebesgue's dominated convergence theorem to obtain \(\frac{\partial (\varphi * \rho^{\epsilon})}{\partial x_j} = \left(\frac{\partial \varphi}{\partial x_j}\right) * \rho^{\epsilon}\).

    The convolution \(\varphi * \rho^{\epsilon}\) has compact support because \(\varphi\) and \(\rho^{\epsilon}\) have also compact support. Therefore, we conclude \(\varphi * \rho^{\epsilon} \in \mathcal{D}\).

    Now, we show \(\varphi * \rho^\epsilon \to \varphi  \text{ in \)\mathcal{D}\( as \)\epsilon \to 0\(}\). First, there exists a compact set \(K\) that contains the support of \(\varphi * \rho^\epsilon\) for all \(\epsilon \in (0,1)\) because \(\varphi\) and \(\rho\) have compact support. Let the support of \(\rho\) be contained in \(B(0,r)\) for some \(r > 0\). For any multi-index \(k\), \(\epsilon \in (0,1)\) and \(x \in K\), we have
    \begin{align*}
        \partial^k(\varphi * \rho^\epsilon) (x) - \partial^k\varphi(x) = \int (\partial^k \varphi(x - y) - \partial^k \varphi(x)) \, \rho^{\epsilon}(y) \mathrm{d}y
    \end{align*}
    because \(\int \rho^{\epsilon}(y) \, \mathrm{d} y = \int \rho(y) \, \mathrm{d} y = 1\). Hence, 
    \begin{align*}
        |\partial^k(\varphi * \rho^\epsilon) (x) - \partial^k\varphi(x)| 
        &\leq \int |\partial^k \varphi(x - y) - \partial^k \varphi(x)| \, |\rho^{\epsilon}(y)| \mathrm{d}y \\
        &\Downarrow \text{Mean value theorem} \\
        & \leq \max_{z \in K_r} |\partial^{k+1}\varphi(z)|  \int  |y| \, |\rho^{\epsilon}(y)| \mathrm{d}y \\
        &\Downarrow \text{Substitution: } y = \epsilon \tilde y \\
        &= \max_{z \in K_r} |\partial^{k+1}\varphi(z)| \, \epsilon  \underbrace{\int  |\tilde y| \, |\rho(\tilde y)| \mathrm{d}\tilde y}_{< \infty}.
    \end{align*}
    As \(\epsilon \to 0\), we see that \(\sup_{x \in K} |\partial^k(\varphi * \rho^\epsilon) (x) - \partial^k\varphi(x)| \to 0\). 
\end{proof}

Next, we can study the effect of applying a distribution \(F\) on \(\varphi * \rho^\epsilon\), where \(\rho\) is a mollifier. We know that \(\varphi * \rho^{\epsilon} \to \varphi\) in \(\mathcal{D}\) as \(\epsilon \to 0\). Then, \(F(\varphi * \rho^{\epsilon}) \to F(\varphi)\) because \(F\) is a distribution. \(F(\varphi * \rho^{\epsilon})\) is also known as a \emph{mollified distribution}. We have the following result for mollified distributions.

\begin{lemma}
    Let \(F \in \mathcal{D}'\). Let \(\varphi \in \mathcal{D}\) and \(g\) be locally integrable and compactly supported. Then,
    \begin{align}\label{lemma:mollified-distribution}
        F(\varphi * g) = \int_{\mathbb{R}^d} F(\varphi_y)g(y) \, \mathrm{d}y.
    \end{align}
\end{lemma}

\begin{proof}
    This follows from linearity of \(F\) and Riemann sum approximation; see Lemma 4.12 in \cite{JanKristensenDistribution}.
    %\begin{align*}
    %    F(\varphi * g) = F\left(\int_{\mathbb{R}} \varphi(x-y) g(y) \, \mathrm{d}y\right) = F\left( 
    %        \lim_{N \to \infty} \sum^N_{k=0} \varphi(x - \xi_k)g(\xi_k)(\xi_{k+1} - \xi)
    %     \right)
    %\end{align*}
\end{proof}

If we let \(g = \rho\), we obtain the crucial relationship \(\int F(\varphi_y)\rho^{\epsilon}(y) \, \mathrm{d}y \to F(\varphi)\) as \(\epsilon \to 0\); or equivalently
\begin{align}\label{eq:starting-point}
    \int F(\rho_y^\epsilon) \varphi(y)\, \mathrm{d}y \to F(\varphi) \quad \text{ as } \epsilon \to 0.
\end{align}
This is \emph{key} to proving the Reconstruction Theorem. 

For future reference, we state the following corollary.
\begin{corollary}\label{cor:minosokoad}
    Let \(F \in \mathcal{D}'\) and \(g,h, \psi \in \mathcal{D}\). Then, 
    \begin{align*}
        \int_{\mathbb{R}^d} F((g*h)_z) \psi(z)\, \mathrm{d}z
    = \iint_{\mathbb{R}^{d \times d}} F(g_y)  h(y-z) \psi(z) \, \mathrm{d}y\, \mathrm{d}z.
    \end{align*}
\end{corollary}

\begin{proof}
    Note that \((g*h)_z(x) = (g*h)(x - z) = \int g(y)h(x-z-y) \, \mathrm{d}y = (g*h_z)(x)\). Using \eqref{lemma:mollified-distribution} we get \(F((g*h)_z) = F(g*h_z) = \int F(g_y) h_z(y) \, \mathrm{d}y\). This proves the corollary.
\end{proof}
